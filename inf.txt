celery -A StorefrontBackend2 beat
celery -A StorefrontBackend2 flower
pwd or py.test

locust -f locustfiles/browse_products.py
docker run -d -p 6379:6379 redis 

silk use localhost:8000/silk/ of our project

install whitenoise: dajngo does't support serving static files in production even though we collect them using cmd  
collectstatic but to add this feature in production we have to install library whitenoise,using
whitenoise we can serve our collected statics in production as well.

we can make our app pwa(for mobile non native app of same web)

# ---- #
# -----git global
# echo "https://${GH_USERNAME}:${GH_TOKEN}@github.com" > ~/.git-credentials

# This will create the ~/.git-credentials file and write the contents of your environment variables to it. The ${GH_USERNAME} and ${GH_TOKEN} syntax is used to reference the values of the environment variables.

# To configure Git to use the credentials stored in the ~/.git-credentials file, you can run the following command:

# lua

# git config --global credential.helper store

# This will set the Git global configuration setting credential.helper to store, which tells Git to use the contents of the ~/.git-credentials file for authentication.
# ---- #
# -----git global


#----SOME USEFUL CMDS----#
python3 manage.py loaddata data.json
sudo fuser -k 8000/tcp
python3 manage.py dbbackup
python3 manage.py dbrestore
#----SOME USEFUL CMDS----#

# ------WAY TO TAG IMAGE------
docker tag lifesyncnow-backend:latest qandeelhaider/lifesyncnow-backend:latest

docker inspect my-postgres-container | grep IPAddress

docker-compose run web python3 manage.py migrate
docker exec -it container_id python manage.py migrate
docker-compose exec app python manage.py makemigrations
docker push qandeelhaider/lifesyncnow-backend:latest
chmod a+x wait-for-it.sh
docker-compose logs web
docker volume ls
# ------WAY TO TAG IMAGE------

# -----------BACKUP AND RESTORE POSTGRES DB FOR LIFESYNCNOW-----------#
# ON LOCAL MACHINE:
docker exec -t my-postgres-container pg_dumpall -c -U postgres > dump_`date +%d-%m-%Y"_"%H_%M_%S`.sql
docker-compose exec db pg_dump -U postgres -Fc postgres > my_backup.dump
# restore data
cat dump_data.sql | docker exec -i my-postgres-container psql -U postgres
# ON LOCAL MACHINE FROM VPS/DROPLET:
docker-compose -f docker-compose.prod.yml exec -T lifesyncnow-db pg_dump -U postgres -d postgres > ./lifesyncnow_db_backup.sql
# docker-compose -f docker-compose.prod.yml exec -T lifesyncnow-db pg_restore -U postgres -d postgres < ./lifesyncnow_db_backup.sql
docker-compose -f docker-compose.prod.yml exec -T lifesyncnow-db psql -U postgres -d postgres < ./lifesyncnow_db_backup.sql
# -----------BACKUP AND RESTORE POSTGRES DB FOR LIFESYNCNOW-----------#

# TO CLEAN DB
python3 manage.py flush --no-input

#BACKUP AND RESTORE A WHOLE VOLUME

# EXAMPLE OF A GOOD PROJECT STRUCTURE
https://github.com/DanielArturoAlejoAlvarez/BLOG-ADVANCED-REST-API-WITH-DJANGO-4.1.5-AND-REACT-REDUX/blob/main/core/settings.py
# EXAMPLE OF A GOOD GITHUB PROFILE
https://github.com/RalitsaTerzieva

# defender cleanup command in case we a large scale of traffic on our blog and blocked ip list is so much in db
python manage.py cleanup_django_defender
You can set this up as a daily or weekly cron job to keep the table size down.

# run at 12:24 AM every morning.
24 0 * * * /usr/bin/python manage.py cleanup_django_defender >> /var/log/django_defender_cleanup.log

#-------PROCFILE
# must add ssl/tls for the flower as well in production
i consider lowering the prefetch count to limit the number of unacknowledged tasks being processed simultaneously.
CMD: "celery -A lifesyncnow_backend.celery_app worker --concurrency=1 --prefetch-multiplier=1"
By setting the concurrency to 1, you ensure that only one task is executed at a time. The --prefetch-multiplier=1 option limits the prefetch count to 1, reducing the number of unacknowledged tasks in the worker's queue.

# -----TREE
tree -I 'venv-lifesyncnow-backend|space-lifesyncnow|playground|meta|locustfiles|legal|global_content|DjangoBackup|subscriber|store|like|tag|user_profile|page|paragraph_with_sbs|templates|about'
flower: sleep 5 && celery -A lifesyncnow_backend.celery_app flower --basic_auth=com.qandeelhaider@gmail.com:com.1995
worker: celery -A lifesyncnow_backend.celery_app worker --concurrency=1 --prefetch-multiplier=1 -n lifesyncnow-celery-worker@%h
# websocket connectoin testing tool using npm package wscat
wscat -c ws://websocket-echo.com